{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc, precision_recall_curve\n",
    "from lightning import pytorch as pl\n",
    "from chemprop import data, featurizers, models, nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Create results directory\n",
    "results_dir = 'results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Load training dataset\n",
    "input_path = \"smiles_10449_train_test.csv\"  # Path to dataset\n",
    "smiles_column = 'SMILES'  # Column containing SMILES strings\n",
    "target_columns = ['Toxicity']  # Target column for toxicity\n",
    "df_input = pd.read_csv(input_path)\n",
    "\n",
    "# Preprocess data\n",
    "smis = df_input[smiles_column].values\n",
    "ys = df_input[target_columns].values\n",
    "all_data = [data.MoleculeDatapoint.from_smi(smi, y) for smi, y in zip(smis, ys)]\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "mols = [d.mol for d in all_data]\n",
    "train_indices, val_indices, test_indices = data.make_split_indices(mols, \"random\", (0.8, 0.1, 0.1))\n",
    "train_data, val_data, test_data = data.split_data_by_indices(all_data, train_indices, val_indices, test_indices)\n",
    "\n",
    "# Extract molecular features\n",
    "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "train_dset = data.MoleculeDataset(train_data[0], featurizer)\n",
    "val_dset = data.MoleculeDataset(val_data[0], featurizer)\n",
    "test_dset = data.MoleculeDataset(test_data[0], featurizer)\n",
    "train_loader = data.build_dataloader(train_dset, num_workers=0)\n",
    "val_loader = data.build_dataloader(val_dset, num_workers=0, shuffle=False)\n",
    "test_loader = data.build_dataloader(test_dset, num_workers=0, shuffle=False)\n",
    "\n",
    "# Define custom model\n",
    "class MyMPNNModel(models.MPNN):\n",
    "    def __init__(self, mp, agg, ffn, batch_norm, metric_list):\n",
    "        super().__init__(mp, agg, ffn, batch_norm, metric_list)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = {\n",
    "            'scheduler': ReduceLROnPlateau(optimizer, factor=0.5, patience=5, verbose=True),\n",
    "            'monitor': 'val_loss',\n",
    "            'frequency': 1,\n",
    "        }\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': lr_scheduler,\n",
    "        }\n",
    "\n",
    "# Initialize model\n",
    "mp = nn.BondMessagePassing()\n",
    "agg = nn.MeanAggregation()\n",
    "ffn = nn.BinaryClassificationFFN(n_tasks=1)\n",
    "batch_norm = False\n",
    "metric_list = None\n",
    "mpnn = MyMPNNModel(mp, agg, ffn, batch_norm, metric_list)\n",
    "\n",
    "# Set up training configuration\n",
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    enable_checkpointing=True,\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    max_epochs=20,\n",
    "    callbacks=[pl.callbacks.ModelCheckpoint(dirpath=results_dir, monitor='val_loss', save_top_k=1)],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(mpnn, train_loader, val_loader)\n",
    "\n",
    "# Save the best model checkpoint\n",
    "best_model_path = os.path.join(results_dir, 'best_model.ckpt')\n",
    "trainer.save_checkpoint(best_model_path)\n",
    "\n",
    "# Evaluate model on test set\n",
    "with torch.inference_mode():\n",
    "    test_preds = trainer.predict(mpnn, test_loader)\n",
    "\n",
    "test_preds = np.concatenate([pred.numpy() for pred in test_preds], axis=0)\n",
    "y_true = df_input.iloc[test_indices[0]][target_columns[0]].values.flatten()\n",
    "y_pred = test_preds.flatten()\n",
    "y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_true, y_pred_binary)\n",
    "f1 = f1_score(y_true, y_pred_binary)\n",
    "precision = precision_score(y_true, y_pred_binary)\n",
    "recall = recall_score(y_true, y_pred_binary)\n",
    "\n",
    "print(f\"Binary Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Binary F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(results_dir, 'roc_curve.png'))\n",
    "\n",
    "# Load unknown compounds for prediction\n",
    "unknown_input_path = \"Water_pollutants.csv\"  # Path to unknown compounds dataset\n",
    "unknown_df = pd.read_csv(unknown_input_path)\n",
    "unknown_smis = unknown_df[smiles_column].values\n",
    "\n",
    "# Reload the best model for prediction\n",
    "mpnn = MyMPNNModel.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# Prepare unknown compounds for prediction\n",
    "unknown_data = [data.MoleculeDatapoint.from_smi(smi, None) for smi in unknown_smis]\n",
    "unknown_dset = data.MoleculeDataset(unknown_data, featurizer)\n",
    "unknown_loader = data.build_dataloader(unknown_dset, num_workers=0, shuffle=False)\n",
    "\n",
    "# Predict unknown compounds\n",
    "with torch.inference_mode():\n",
    "    unknown_preds = trainer.predict(mpnn, unknown_loader)\n",
    "\n",
    "unknown_preds = np.concatenate([pred.numpy() for pred in unknown_preds], axis=0)\n",
    "unknown_preds_binary = [1 if p >= 0.5 else 0 for p in unknown_preds.flatten()]\n",
    "\n",
    "# Save predictions for unknown compounds\n",
    "unknown_output_df = pd.DataFrame({\n",
    "    'Compound_Name': unknown_df['ID'],  # Assuming an ID column exists\n",
    "    'SMILES': unknown_df[smiles_column].values,\n",
    "    'Predicted_Toxicity': unknown_preds_binary\n",
    "})\n",
    "unknown_output_df.to_csv(os.path.join(results_dir, 'Water_pollutants_predictions.csv'), index=False)\n",
    "\n",
    "print(\"Prediction complete. Results saved to 'results/Water_pollutants_predictions.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
